{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d27ce84-f09c-49cf-a75d-bb9412f4aa02",
   "metadata": {},
   "source": [
    "# Opening files from URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433571c3-d3a4-4ece-93fc-ae74c05e69d5",
   "metadata": {},
   "source": [
    "Why would you want to open files from URLs within a Jupyter Notebook or a Python script?\n",
    "\n",
    "1. You want your code to be portable without needing to transport the data (like for teaching!)\n",
    "2. You want to use a public data set but you don't need it or want it on your computer\n",
    "3. You're using Google Colab, which doesn't access your files\n",
    "4. You want to provide data to download within your notebook or script\n",
    "5. You are unable to download data to your computer\n",
    "\n",
    "\n",
    "<br>There are two different things you might want to do:\n",
    "\n",
    "- Download the file to your computer (or to your Colab workspace) and then open it now or later. (You have the data even after you close the notebook.)\n",
    "\n",
    "- Open the file from the web without downloading it. (You won't have it after you close your notebook - but you can save it to a file locally before closing your notebook if you need to.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c80a07-220e-47c7-a2bd-7f7740516745",
   "metadata": {},
   "source": [
    "### Practice data\n",
    "I've collected a few datasets for us to practice on today, from public sources.\n",
    "- **fastestAnimals**: From **GitHub repo** for one of my other workshops. Top recorded speeds of the twenty fastest animals in the world. **Format: txt**\n",
    "- **trafficCounts**: From **data.gov**. A close approximation to the actual number of vehicles passing through a given location in Chicago on an average weekday. **Format: csv**\n",
    "- **covidSewer**:  From **data.gov**. Concentrations of the COVID-19 virus gene in the Chicago sewer system, as measured at eight sewershed sites. **Format: xml**\n",
    "- **missedWork**: From **UC Irvine Machine Learning Repository**. Records of absenteeism at work from July 2007 to July 2010 at a courier company in Brazil. **Format: zip**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe07326-8b20-4a34-b9f7-d430a74e1d9d",
   "metadata": {},
   "source": [
    "Let's store the URL to each dataset as a string variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42736bbf-a4e3-4f75-9873-00633064559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covidSewer = \"https://data.cityofchicago.org/api/views/urdi-w8wq/rows.xml\"\n",
    "missedWork = \"https://archive.ics.uci.edu/static/public/445/absenteeism+at+work.zip\"\n",
    "fastestAnimals = \"https://raw.githubusercontent.com/nuitrcs/NextStepsInPython/master/pickleJson/fastestAnimals.txt\"\n",
    "trafficCounts = \"https://data.cityofchicago.org/api/views/pfsx-4n4m/rows.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0b3f30-030c-4b9e-82af-f84a208f088c",
   "metadata": {},
   "source": [
    "### <br><br>Opening data without downloading it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b051f-25aa-4c85-8ae9-29850617c79d",
   "metadata": {},
   "source": [
    "First, let's try to open one of these files the way we would normally in Python. We'll try the least complex file, the txt file. The URL is saved as `fastestAnimals`. As a reminder, `f.read()` will turn the file into one long string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328cf8d-794c-4c47-9f8a-28ea8ef456d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fastestAnimals, \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50701ad-c34a-4812-9db9-1d4286945ce2",
   "metadata": {},
   "source": [
    "<br><br>It's always worth a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6100f48-e0ea-4e79-b064-e26b42784818",
   "metadata": {},
   "source": [
    "<br>We're going to import the **request** object from the package **urllib**. It is a built-in Python package, so everyone has it on their computer, it just needs to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2a824-2490-4065-8cba-c136ce523e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a974b585-25da-425d-b67b-0187cc26e4a9",
   "metadata": {},
   "source": [
    "<br>Now we can open the file as we normally would, only we will use the function `request.urlopen()`. We do not need to pass it a **mode** because it is only used to read files - there is no mode for writing to a URL, since creating a URL is more complicated than just writing to a filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404dc74c-1a60-44a1-a02a-cbe25c6cd9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with request.urlopen(fastestAnimals) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e8f324-9c3c-4f4b-84c1-9ac5afb93cad",
   "metadata": {},
   "source": [
    "<br><br>That worked! Sort of...\n",
    "\n",
    "<br><br>Notice there is a \"b\" in front of the string and there are a couple strange special characters in there. We know the tabs (`\\t`) and the new lines (`\\n`), but what about the `\\xe2\\x80\\x93` and other strange code?\n",
    "<br><br>By default, `request.urlopen()` will open every file as a **bytes** object. \n",
    "<br><br>Luckily, there is a simple Python string method function called `decode()` that will interpret those bytes and return a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bf735a-04fb-4c42-9185-ca3f95e822e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with request.urlopen(fastestAnimals) as f:\n",
    "    str_f = f.read().decode()\n",
    "print(str_f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea98d9-bc16-46b8-9fda-438caf3a3ced",
   "metadata": {},
   "source": [
    "#### <br><br>Exercise 1\n",
    "Write code to open and decode the other URL files: `trafficCounts` (csv), `covidSewers` (xml), and `missedWork` (zip). Which ones look clean enough to work with? Which ones would you want to look up a new solution to open?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931198d6-3f2c-4bba-a8fb-7ae5c895dd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c445200-f51a-4dad-b9dd-5b76714b3e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e429f-c0ef-4d59-aac2-f24916878786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be8b42-6bce-476d-b251-c428d5f4d24d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f87a8f1-a215-4482-ab13-203c1186f1d3",
   "metadata": {},
   "source": [
    "<br>There is also the file method function `readlines()` that you can use instead of `read()`. It transforms your file into a list of lines instead of just one long string. Try it out on any of the files that you think might benefit from that format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c29109-22a7-47f3-b6a5-5213e544913b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e137dc-eb6d-4e98-9794-3e042b6fd3ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df036141-32c3-4250-bb66-8f2c64189f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0931c459-0b30-43da-9173-9af6215f52be",
   "metadata": {},
   "source": [
    "### <br><br>Opening csv files from URLs in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f085736-18cc-4204-8b39-27b0ad093f7e",
   "metadata": {},
   "source": [
    "You can always parse a csv file as a string or list of lines or a dictionary, depending on what you need to do with the data (list comprehensions and dictionary comprehensions are great for this). However, your plan might be to open the csv file as a **pandas dataframe**.\n",
    "<br><br>Let's try opening the `trafficCounts` URL as a pandas dataframe the same way we would open any csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fba3c-3f8d-4ea2-a21d-5ff05c54dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1fdcbe-efd0-45d3-b85c-c66909abdc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(trafficCounts)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5487b151-9275-478a-802c-ca08844b5789",
   "metadata": {},
   "source": [
    "<br><br><br>I told you - it's always worth a try!\n",
    "<br><br>The `read_csv()` function can automatically load data from URLs!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a029985d-5c81-4e09-8da3-33e1a1312e36",
   "metadata": {},
   "source": [
    "#### <br><br>Exercise 2.\n",
    "Write code to open the `fastestAnimals` txt file using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba52374-5d60-44b2-990f-0965be4a26d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99575ea3-eb02-40da-9db1-88e54369a9f5",
   "metadata": {},
   "source": [
    "<br>Which parameters can you pass to the `read_csv()` function to make the txt file work better as a dataframe? Check out the documentation to see all the options: https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499b74f1-354b-4377-9b0f-7c5a533cace3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4262dcc-42cf-4fe8-bbb3-f6b63cae32ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8c9c131-82bf-4339-93c9-d388388d0db3",
   "metadata": {},
   "source": [
    "### <br><br>Opening xml data from a URL\n",
    "**xml** is a format used to share data between computer programs. It stores text data in a heirarchy using tags, similar to how HTML marks code. (Maybe we'll do a Lunch Lesson on working with xml data in the future.)\n",
    "<br><br>xml data can contain malicious code, so Python always recommends using the built-in library **defusedxml** to open xml files. It is mostly the same as the built-in library **xml**, but it prevents most major attacks.\n",
    "<br><br>To open an xml file that is saved on your computer, we would normally use the function `ElementTree.parse()`, but that won't work for URLs. Instead, we will open it the same way we learned previously, using the `request.urlopen()` function from urllib, and then using `decode()` to convert it from a bytes object to a string. Then we'll use the `ElementTree.fromstring()` function to convert the string to an xml object. I know it seems like quite a few steps, but it will always be here in this notebook if you ever need it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c0371-a5be-4dcc-85f7-770d5bdcbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defusedxml.ElementTree import fromstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ca8c9-926b-4393-8ca0-9f63e9958beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with request.urlopen(covidSewer) as f:    \n",
    "    yuck = f.read().decode()\n",
    "yuck_xml = fromstring(yuck)\n",
    "print(yuck_xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77383513-38a4-4c3f-96ee-1f07b333bdc2",
   "metadata": {},
   "source": [
    "<br>This is what we'd expect to see for an xml object. It can be further parsed using other methods and attributes of the ElementTree object in the defusedxml library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb3b6b9-7ba1-48dc-a8e8-1b064914bf35",
   "metadata": {},
   "source": [
    "### <br><br>Opening a zip file from a URL\n",
    "A zip file needs to be unzipped! Zip files can contain one or many files of different file types. \n",
    "<br><br>We will use the `ZipFile()` function from the **zipfile** built-in library to open the `missedWork` zip file from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1489d74b-0f6c-47fe-ad05-37b8880e1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51614363-c46b-4d21-b90e-88b1a9156154",
   "metadata": {},
   "source": [
    "<br><br>Let's try what we know. We can open the URL in the `request.urlopen()` function, then read it in, then decode it to convert it from a bytes object, then unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a46131-78bb-4d2e-9ad5-676f76e8dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with request.urlopen(missedWork) as f:\n",
    "    absent_files = ZipFile(f.read().decode())\n",
    "print(absent_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f4bb29-807c-4cfa-b376-1c2d041090ca",
   "metadata": {},
   "source": [
    "<br><br>Ok, that didn't work because `decode()` converts from a bytes object to a string, and a zip file won't work as a string because it's really a folder of files and not a single file. \n",
    "<br><br>We need to bring in a more powerful decoder - `BytesIO()` from the built-in package **io**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72d1a4-1d34-47b2-9e71-e377164f7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d94019-8dbe-4cc5-afa7-75824f2a04bd",
   "metadata": {},
   "source": [
    "<br><br>We use the same logic: We can open the URL in the request.urlopen() function, then read it in, then decode it to convert it from a bytes object, then unzip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b7d3ab-a360-4aa3-88a1-c41271e8738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with request.urlopen(missedWork) as f:\n",
    "    absent_files = ZipFile(BytesIO(f.read()))\n",
    "print(absent_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c09990-8339-417a-9d52-328a88b01f0e",
   "metadata": {},
   "source": [
    "<br><br>This is a zipfile object. We can use other methods in the **zipfile** library to do more with our unzipped files, but we won't cover that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad069d9-8dca-45ff-b1ac-b13ad535ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_files.namelist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654225a0-8ffb-4a42-9559-4458aa6c9007",
   "metadata": {},
   "source": [
    "### <br><br>Downloading data from URLs\n",
    "Take a look in your file tree on the left menu. We were able to work with all those files without downloading them onto our computer! Instead, we just loaded them into memory within Python. We can now work with that data in this notebook - filter it, analyze it, change it, visualize it - and just save the final products. If we close this notebook and open it in a year, we can reload the data from the URLs, as long as the data still lives at the same URL.\n",
    "\n",
    "<br>Sometimes, though, we want to use a Python script to download data to our computer. Maybe that's the purpose of the script. \n",
    "<br><br>There are a few ways to do this. On a Linux system like Google Colab or a Mac computer, you can use the `!` to let Python know you're going to give a system command, and then use the bash command `wget`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c610ef-2b3c-41b5-b15e-18674c0cbda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/nuitrcs/NextStepsInPython/master/pickleJson/fastestAnimals.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472ba6d0-7bb0-4f47-af04-4aca616f2219",
   "metadata": {},
   "source": [
    "<br>If you are on Colab or a Mac, you should see the file pop up in your file tree (might take a minute)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e409ab-425d-4f91-afb0-6ed1ffd82e91",
   "metadata": {},
   "source": [
    "<br><br>A second way to download data from a url, that should work for all Operating Systems because it's in Python and not command line, is a function in the **urllib** library called `request.urlretrieve()`. We already installed `request` from `urllib` in this notebook, so we're good to go.\n",
    "<br><br>The function takes two arguments - the url to pull from, and the path where it should be saved. We will save the file right here in our current working directory, so our path will just be the filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5855f-fe9b-4be6-a0eb-299d88835469",
   "metadata": {},
   "outputs": [],
   "source": [
    "request.urlretrieve(fastestAnimals, \"secondFastestAnimals.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ea2b8-0dd2-4c95-a6d4-a4ce2cea7b2a",
   "metadata": {},
   "source": [
    "<br>Hopefully that worked for you, and you see the file pop up in your file tree after a minute. Because we didn't give it a path to a different folder, the file is saved in the same folder where this notebook is located. The message that got printed to the screen starts with the path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99d14c-1535-454d-9514-16bac3925651",
   "metadata": {},
   "source": [
    "#### <br><br>Exercise 3.\n",
    "Write code to download the other files from the URLs we saved: `missedWork` (zip), `trafficCounts` (csv), and `covidSewer` (xml). Think up your own name for the files, or try leaving the second argument off for one file and find out where the file is saved and what it gets named if you don't give a path. If you're naming your own file, remember to give the filename the correct extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc509d2-d4d4-4962-9422-d3a6e2af9f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a9e2a2-5a28-44bb-9f59-1b016d1750b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74603d1-81b5-4d75-bce4-1de2fe179371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5791ae73-6970-493e-a550-69972e9080d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8b40c48-5633-430d-a0f8-c8621c4b3c2d",
   "metadata": {},
   "source": [
    "Try saving one file to a different location on your computer by passing an absolute path like \"~/Downloads/my_file.ext\". If you're on Colab, you can save it in the \"sample_data\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f00db-ebb6-4b7d-8368-21132da1f7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e8e92-1312-45e9-a2e5-dbe4aec22970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d4ece9-2509-4cbb-a216-a6549e29ef41",
   "metadata": {},
   "source": [
    "#### <br><br>How to get the correct URL from a GitHub repo\n",
    "In the repo, click on the name of the file. Then click on the button `Raw` on the top right of the file. Copy the URL from that page. You can also right click on the `Raw` button and choose Copy link address, or the equivalent command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67083f-b220-4126-a188-ac8cfdb64195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
